[
  {
    "objectID": "fad_gen.html",
    "href": "fad_gen.html",
    "title": "fad_gen",
    "section": "",
    "text": "This program may not be needed if you already have directories of real & fake audio."
  },
  {
    "objectID": "fad_gen.html#sample-calling-sequences",
    "href": "fad_gen.html#sample-calling-sequences",
    "title": "fad_gen",
    "section": "Sample calling sequence(s):",
    "text": "Sample calling sequence(s):\nSingle GPU, local data:\nfad_gen test autoencoder.ts \"real1/ real2/ real3/\"\nMultiple GPUs, data on S3:\naccelerate launch fad_pytorch/fad_gen.py 5s_simple model_checkpoint.ts \"s3://s-laion-audio/webdataset_tar/freesound_no_overlap/ s3://s-laion-audio/webdataset_tar/epidemic_sound_effects/\" -p \"{'s3://s-laion-audio':'default'}\"\nGeneral calling sequence:\n$ fad_gen -h\nusage: fad_gen [-h] [-b BATCH_SIZE] [--n N] [--num_workers NUM_WORKERS] [-p PROFILES] [--sample_rate SAMPLE_RATE] [-s SAMPLE_SIZE]\n               name model_ckpt data_sources\n\npositional arguments:\n  name                  Name prefix for output directories: &lt;name&gt;_reals/ & &lt;name&gt;_fakes/\n  model_ckpt            TorchScript (.ts) (Generative) Model checkpoint file\n  data_sources          Space-separated string listing either S3 resources or local directories (but not a mix of both!) for real data\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -b BATCH_SIZE, --batch_size BATCH_SIZE\n                        batch size (default: 2)\n  --n N                 Number of real/fake samples to grab/generate, respectively (default: 256)\n  --num_workers NUM_WORKERS\n                        Number of pytorch workers to use in DataLoader (default: 12)\n  -p PROFILES, --profiles PROFILES\n                        String representation of dict {resource:profile} (default: )\n  --sample_rate SAMPLE_RATE\n                        sample rate (will resample inputs at this rate) (default: 48000)\n  -s SAMPLE_SIZE, --sample_size SAMPLE_SIZE\n                        Number of samples per clip (default: 262144)\n\nsource\n\ngen\n\n gen (args)\n\n\nsource\n\n\nmain\n\n main ()"
  },
  {
    "objectID": "fad_embed.html",
    "href": "fad_embed.html",
    "title": "fad_embed",
    "section": "",
    "text": "Single processor, single GPU:\nfad_embed clap real/ fake\nMultiple GPUs, multiple processors (single node): (this example syntax is to run from within main fad_pytorch package directory)\naccelerate launch fad_pytorch/fad_embed.py clap real/ fake/\nGeneral invocation:\n$ fad_embed -h\nusage: fad_embed [-h] [--batch_size BATCH_SIZE] [--sample_size SAMPLE_SIZE] [--chunk_size CHUNK_SIZE] [--hop_size HOP_SIZE] [--max_hops MAX_HOPS] [--sr SR] [--verbose]\n                 [--debug]\n                 embed_model real_path fake_path\n\npositional arguments:\n  embed_model           choice of embedding model(s): clap | vggish | pann | openl3 | all\n  real_path             Path of files of real audio\n  fake_path             Path of files of fake audio\n\noptions:\n  -h, --help            show this help message and exit\n  --batch_size BATCH_SIZE\n                        MAXIMUM Batch size for computing embeddings (may go smaller) (default: 64)\n  --sample_size SAMPLE_SIZE\n                        Number of audio samples to read from each audio file (default: 262144)\n  --chunk_size CHUNK_SIZE\n                        Length of chunks (in audio samples) to embed (default: 24000)\n  --hop_size HOP_SIZE   (approximate) time difference (in seconds) between each chunk (default: 0.1)\n  --max_hops MAX_HOPS   Don't exceed this many hops/chunks/embeddings per audio file. &lt;= 0 disables this. (default: -1)\n  --sr SR               sample rate (will resample inputs at this rate) (default: 48000)\n  --verbose             Show notices of resampling when reading files (default: False)\n  --debug               Extra messages for debugging this program (default: False)\nFirst a couple utilities for downloading checkpoints:\n\nsource\n\n\n\n get_ckpt (ckpt_file='music_speech_audioset_epoch_15_esc_89.98.pt',\n           ckpt_base_url='https://huggingface.co/lukewys/laion_clap/blob/m\n           ain', ckpt_dl_path='/home/runner/checkpoints',\n           accelerator=None)\n\n\nsource\n\n\n\n\n download_if_needed (url, local_filename, accelerator=None)\n\nwrapper for download file\n\nsource\n\n\n\n\n download_file (url, local_filename)\n\nIncludes a progress bar. from https://stackoverflow.com/a/37573701/4259243\n\nsource\n\n\n\n\n setup_embedder (model_choice='clap', device='cuda',\n                 ckpt_file='music_speech_audioset_epoch_15_esc_89.98.pt', \n                 ckpt_base_url='https://huggingface.co/lukewys/laion_clap/\n                 resolve/main', accelerator=None,\n                 ckpt_dl_path='/home/runner/checkpoints')\n\nload the embedder model\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel_choice\nstr\nclap\n‘clap’ | ‘vggish’ | ‘pann’\n\n\ndevice\nstr\ncuda\n\n\n\nckpt_file\nstr\nmusic_speech_audioset_epoch_15_esc_89.98.pt\nNOTE: ‘CLAP_CKPT’ env var overrides ckpt_file kwarg\n\n\nckpt_base_url\nstr\nhttps://huggingface.co/lukewys/laion_clap/resolve/main\n\n\n\naccelerator\nNoneType\nNone\nhttps://huggingface.co/lukewys/laion_clap/resolve/main/music_speech_audioset_epoch_15_esc_89.98.pt\n\n\nckpt_dl_path\nstr\n/home/runner/checkpoints\n\n\n\n\n\nembedder, sample_rate = setup_embedder('openl3','cuda')\n\n/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n  return f(*args, **kwargs)\nDownloading: \"https://github.com/torchopenl3/torchopenl3-models/raw/master/torchopenl3_mel256_music_512.pth.tar\" to /home/shawley/.cache/torch/hub/checkpoints/torchopenl3_mel256_music_512.pth.tar\n100%|██████████| 34.9M/34.9M [00:00&lt;00:00, 249MB/s]\n\n\n\nsource\n\n\n\n\n embed (args)\n\n\nsource\n\n\n\n\n main ()"
  },
  {
    "objectID": "fad_embed.html#sample-calling-sequences",
    "href": "fad_embed.html#sample-calling-sequences",
    "title": "fad_embed",
    "section": "",
    "text": "Single processor, single GPU:\nfad_embed clap real/ fake\nMultiple GPUs, multiple processors (single node): (this example syntax is to run from within main fad_pytorch package directory)\naccelerate launch fad_pytorch/fad_embed.py clap real/ fake/\nGeneral invocation:\n$ fad_embed -h\nusage: fad_embed [-h] [--batch_size BATCH_SIZE] [--sample_size SAMPLE_SIZE] [--chunk_size CHUNK_SIZE] [--hop_size HOP_SIZE] [--max_hops MAX_HOPS] [--sr SR] [--verbose]\n                 [--debug]\n                 embed_model real_path fake_path\n\npositional arguments:\n  embed_model           choice of embedding model(s): clap | vggish | pann | openl3 | all\n  real_path             Path of files of real audio\n  fake_path             Path of files of fake audio\n\noptions:\n  -h, --help            show this help message and exit\n  --batch_size BATCH_SIZE\n                        MAXIMUM Batch size for computing embeddings (may go smaller) (default: 64)\n  --sample_size SAMPLE_SIZE\n                        Number of audio samples to read from each audio file (default: 262144)\n  --chunk_size CHUNK_SIZE\n                        Length of chunks (in audio samples) to embed (default: 24000)\n  --hop_size HOP_SIZE   (approximate) time difference (in seconds) between each chunk (default: 0.1)\n  --max_hops MAX_HOPS   Don't exceed this many hops/chunks/embeddings per audio file. &lt;= 0 disables this. (default: -1)\n  --sr SR               sample rate (will resample inputs at this rate) (default: 48000)\n  --verbose             Show notices of resampling when reading files (default: False)\n  --debug               Extra messages for debugging this program (default: False)\nFirst a couple utilities for downloading checkpoints:\n\nsource\n\n\n\n get_ckpt (ckpt_file='music_speech_audioset_epoch_15_esc_89.98.pt',\n           ckpt_base_url='https://huggingface.co/lukewys/laion_clap/blob/m\n           ain', ckpt_dl_path='/home/runner/checkpoints',\n           accelerator=None)\n\n\nsource\n\n\n\n\n download_if_needed (url, local_filename, accelerator=None)\n\nwrapper for download file\n\nsource\n\n\n\n\n download_file (url, local_filename)\n\nIncludes a progress bar. from https://stackoverflow.com/a/37573701/4259243\n\nsource\n\n\n\n\n setup_embedder (model_choice='clap', device='cuda',\n                 ckpt_file='music_speech_audioset_epoch_15_esc_89.98.pt', \n                 ckpt_base_url='https://huggingface.co/lukewys/laion_clap/\n                 resolve/main', accelerator=None,\n                 ckpt_dl_path='/home/runner/checkpoints')\n\nload the embedder model\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel_choice\nstr\nclap\n‘clap’ | ‘vggish’ | ‘pann’\n\n\ndevice\nstr\ncuda\n\n\n\nckpt_file\nstr\nmusic_speech_audioset_epoch_15_esc_89.98.pt\nNOTE: ‘CLAP_CKPT’ env var overrides ckpt_file kwarg\n\n\nckpt_base_url\nstr\nhttps://huggingface.co/lukewys/laion_clap/resolve/main\n\n\n\naccelerator\nNoneType\nNone\nhttps://huggingface.co/lukewys/laion_clap/resolve/main/music_speech_audioset_epoch_15_esc_89.98.pt\n\n\nckpt_dl_path\nstr\n/home/runner/checkpoints\n\n\n\n\n\nembedder, sample_rate = setup_embedder('openl3','cuda')\n\n/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n  return f(*args, **kwargs)\nDownloading: \"https://github.com/torchopenl3/torchopenl3-models/raw/master/torchopenl3_mel256_music_512.pth.tar\" to /home/shawley/.cache/torch/hub/checkpoints/torchopenl3_mel256_music_512.pth.tar\n100%|██████████| 34.9M/34.9M [00:00&lt;00:00, 249MB/s]\n\n\n\nsource\n\n\n\n\n embed (args)\n\n\nsource\n\n\n\n\n main ()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "fad_pytorch",
    "section": "",
    "text": "Original FAD paper (PDF)"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "fad_pytorch",
    "section": "Install",
    "text": "Install\npip install fad_pytorch"
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "fad_pytorch",
    "section": "Features:",
    "text": "Features:\n\nruns in parallel on multiple processors and multiple GPUs (via accelerate)\nsupports multiple embedding methods:\n\nVGGish and PANN, both mono @ 16kHz\nOpenL3 and (LAION-)CLAP, stereo @ 48kHz\n\nuses publicly-available pretrained checkpoints for music (+other sources) for those models. (if you want Speech, submit a PR or an Issue; I don’t do speech.)\nfavors ops in PyTorch rather than numpy (or tensorflow)\nfad_gen supports local data read or WebDataset (audio data stored in S3 buckets)\nruns on CPU, CUDA, or MPS"
  },
  {
    "objectID": "index.html#instructions",
    "href": "index.html#instructions",
    "title": "fad_pytorch",
    "section": "Instructions:",
    "text": "Instructions:\nThis is designed to be run as 3 command-line scripts in succession. The latter 2 (fad_embed and fad_score) are probably what most people will want:\n\nfad_gen: produces directories of real & fake audio (given real data). See fad_gen documentation for calling sequence.\nfad_embed [options] &lt;real_audio_dir&gt; &lt;fake_audio_dir&gt;: produces directories of embeddings of real & fake audio\nfad_score [options] &lt;real_emb_dir&gt; &lt;fake_emb_dir&gt;: reads the embeddings & generates FAD score, for real (“\\(r\\)”) and fake (“\\(f\\)”):\n\n\\[ FAD = || \\mu_r - \\mu_f ||^2 + tr\\left(\\Sigma_r + \\Sigma_f - 2 \\sqrt{\\Sigma_r \\Sigma_f}\\right)\\]"
  },
  {
    "objectID": "index.html#documentation",
    "href": "index.html#documentation",
    "title": "fad_pytorch",
    "section": "Documentation",
    "text": "Documentation\nSee the Documentation Website."
  },
  {
    "objectID": "index.html#comments-faq-troubleshooting",
    "href": "index.html#comments-faq-troubleshooting",
    "title": "fad_pytorch",
    "section": "Comments / FAQ / Troubleshooting",
    "text": "Comments / FAQ / Troubleshooting\n\n“RuntimeError: CUDA error: invalid device ordinal”: This happens when you have a “bad node” on an AWS cluster. Haven’t yet figured out what causes it or how to fix it. Workaround: Just add the current node to your SLURM --exclude list, exit and retry. Note: it may take as many as 5 to 7 retries before you get a “good node”.\n“FAD scores obtained from different embedding methods are wildly different!” …Yea. It’s not obvious that scores from different embedding methods should be comparable. Rather, compare different groups of audio files using the same embedding method, and/or check that FAD scores go down as similarity improves.\n“FAD score for the same dataset repeated (twice) is not exactly zero!” …Yea. There seems to be an uncertainty of around +/- 0.008. I’d say, don’t quote any numbers past the first decimal point."
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "fad_pytorch",
    "section": "Contributing",
    "text": "Contributing\nThis repo is still fairly “bare bones” and will benefit from more documentation and features as time goes on. Note that it is written using nbdev, so the things to do are:\n\nFork this repo\nClone your fork to your (local) machine\nInstall nbdev: python3 -m pip install -U nbdev\nMake changes by editing the notebooks in nbs/, not the .py files in fad_pytorch/.\nRun nbdev_export to export notebook changes to .py files\nFor good measure, run nbdev_install_hooks and nbdev_clean - especially if you’ve added any notebooks.\nDo a git status to see all the .ipynb and .py files that need to be added & committed\ngit add those files and then git commit, and then git push\nTake a look in your fork’s GitHub Actions tab, and see if the “test” and “deploy” CI runs finish properly (green light) or fail (red light)\nOnce you get green lights, send in a Pull Request!\n\nFeel free to ask me for tips with nbdev, it has quite a learning curve. You can also ask on fast.ai forums and/or fast.ai Discord"
  },
  {
    "objectID": "index.html#citations-blame-disclaimer",
    "href": "index.html#citations-blame-disclaimer",
    "title": "fad_pytorch",
    "section": "Citations / Blame / Disclaimer",
    "text": "Citations / Blame / Disclaimer\nThis repo is 2 weeks old. I’m not ready for this to be cited in your papers. I’d hate for there to be some mistake I haven’t found yet. Perhaps a later version will have citation info. For now, instead, there’s:\nDisclaimer: Results from this repo are still a work in progress. While every effort has been made to test model outputs, the author takes no responsbility for mistakes. If you want to double-check via another source, see “Related Repos” below."
  },
  {
    "objectID": "index.html#related-repos",
    "href": "index.html#related-repos",
    "title": "fad_pytorch",
    "section": "Related Repos",
    "text": "Related Repos\nThere are [several] others, but this one is mine. These repos didn’t have all the features I wanted, but I used them for inspiration:\n\nhttps://github.com/gudgud96/frechet-audio-distance\nhttps://github.com/google-research/google-research/tree/master/frechet_audio_distance: Goes with Original FAD paper\nhttps://github.com/AndreevP/speech_distances"
  },
  {
    "objectID": "fad_score.html",
    "href": "fad_score.html",
    "title": "fad_score",
    "section": "",
    "text": "\\[ FAD = || \\mu_r - \\mu_f ||^2 + tr\\left(\\Sigma_r + \\Sigma_f - 2 \\sqrt{\\Sigma_r \\Sigma_f}\\right)\\]\nThe embeddings are small enough that this can typically be run on a single processor, on a CPU. However, all the supporting code is GPU-friendly if so desired.\n\nsource\n\nread_embeddings\n\n read_embeddings (emb_path='real_emb_clap/', debug=False)\n\nreads any .pt files in emb_path and concatenates them into one tensor\n\n# lil test of that\ne = read_embeddings()\ne.shape\n\ntorch.Size([256, 512])\n\n\n\nsource\n\n\ncalc_mu_sigma\n\n calc_mu_sigma (emb)\n\ncalculates mean and covariance matrix of batched embeddings\n\n# quick test:\nx = torch.rand(32,512) \nmu, sigma = calc_mu_sigma(x) \nmu.shape, sigma.shape\n\n(torch.Size([512]), torch.Size([512, 512]))\n\n\n\nsource\n\n\ncalc_score\n\n calc_score (real_emb_path, fake_emb_path, method='maji', debug=False)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nreal_emb_path\n\n\nwhere real embeddings are stored\n\n\nfake_emb_path\n\n\nwhere fake embeddings are stored\n\n\nmethod\nstr\nmaji\nsqrtm calc method: ‘maji’|‘li’\n\n\ndebug\nbool\nFalse\n\n\n\n\nTest the score function:\n\nscore = calc_score( 'real_emb_clap/', 'fake_emb_clap/', method='maji')\nprint(score)\n\nCalculating FAD score for files in real_emb_clap// vs. fake_emb_clap//\ntensor(0.0951)\n\n\nTry sending using the exact same data for both distributions: Do we get zero?\n\nscore = calc_score( 'real_emb_clap/', 'real_emb_clap/', method='maji', debug=True)\nprint(score)\n\nCalculating FAD score for files in real_emb_clap// vs. real_emb_clap//\nsearching in  real_emb_clap/\nsearching in  real_emb_clap/\ntorch.Size([256, 512]) torch.Size([256, 512])\nmu_real.shape, sigma_real.shape = torch.Size([512]) torch.Size([512, 512])\nmu_fake.shape, sigma_fake.shape = torch.Size([512]) torch.Size([512, 512])\nmu_diff =  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.])\nscore1: mu_diff.dot(mu_diff) =  tensor(0.)\nscore2: torch.trace(sigma_real) =  tensor(0.4448)\nscore3: torch.trace(sigma_fake) =  tensor(0.4448)\nscore_p.shape (matmul) =  torch.Size([512, 512])\nscore4 (-2*tr(sqrtm(matmul(sigma_r sigma_f))))  =  tensor(-0.8888)\ntensor(0.0008)\n\n\nOk, so not zero, but small.\n\nsource\n\n\nmain\n\n main ()"
  },
  {
    "objectID": "sqrtm.html",
    "href": "sqrtm.html",
    "title": "sqrtm",
    "section": "",
    "text": "source\n\n\n\n MatrixSquareRoot_li (*args, **kwargs)\n\nFrom https://github.com/steveli/pytorch-sqrtm/blob/master/sqrtm.py, which sadly does not install as a package. LICENSE included below Square root of a positive definite matrix.\nNOTE: matrix square root is not differentiable for matrices with zero eigenvalues.\nSteve Li’s test code for the above:\n\nfrom torch.autograd import gradcheck\n\n\nif use_li:\n    k = torch.randn(1000, 1000).double()\n    # Create a positive definite matrix\n    pd_mat = (k.t().matmul(k)).requires_grad_()\n    with torch.no_grad():\n        sq = sqrtm_li(pd_mat)\n    print(\"sq =\\n\",sq)\n    #print(\"Running gradcheck...\")\n    #test = gradcheck(sqrtm_li, (pd_mat,))\n    #print(test)\n\nsq =\n tensor([[ 2.6360e+01, -5.2896e-01,  4.6020e-01,  ...,  4.6385e-01,\n         -2.5534e-01,  3.3804e-01],\n        [-5.2896e-01,  2.5773e+01, -7.2415e-01,  ..., -2.6621e-02,\n          3.0918e-01, -7.8089e-02],\n        [ 4.6020e-01, -7.2415e-01,  2.5863e+01,  ..., -5.2346e-01,\n          1.4617e-01, -2.5943e-01],\n        ...,\n        [ 4.6385e-01, -2.6621e-02, -5.2346e-01,  ...,  2.6959e+01,\n          3.6158e-01, -4.6653e-01],\n        [-2.5534e-01,  3.0918e-01,  1.4617e-01,  ...,  3.6158e-01,\n          2.6692e+01, -4.4417e-01],\n        [ 3.3804e-01, -7.8089e-02, -2.5943e-01,  ..., -4.6653e-01,\n         -4.4417e-01,  2.8916e+01]], dtype=torch.float64)"
  },
  {
    "objectID": "sqrtm.html#steve-lis-method",
    "href": "sqrtm.html#steve-lis-method",
    "title": "sqrtm",
    "section": "",
    "text": "source\n\n\n\n MatrixSquareRoot_li (*args, **kwargs)\n\nFrom https://github.com/steveli/pytorch-sqrtm/blob/master/sqrtm.py, which sadly does not install as a package. LICENSE included below Square root of a positive definite matrix.\nNOTE: matrix square root is not differentiable for matrices with zero eigenvalues.\nSteve Li’s test code for the above:\n\nfrom torch.autograd import gradcheck\n\n\nif use_li:\n    k = torch.randn(1000, 1000).double()\n    # Create a positive definite matrix\n    pd_mat = (k.t().matmul(k)).requires_grad_()\n    with torch.no_grad():\n        sq = sqrtm_li(pd_mat)\n    print(\"sq =\\n\",sq)\n    #print(\"Running gradcheck...\")\n    #test = gradcheck(sqrtm_li, (pd_mat,))\n    #print(test)\n\nsq =\n tensor([[ 2.6360e+01, -5.2896e-01,  4.6020e-01,  ...,  4.6385e-01,\n         -2.5534e-01,  3.3804e-01],\n        [-5.2896e-01,  2.5773e+01, -7.2415e-01,  ..., -2.6621e-02,\n          3.0918e-01, -7.8089e-02],\n        [ 4.6020e-01, -7.2415e-01,  2.5863e+01,  ..., -5.2346e-01,\n          1.4617e-01, -2.5943e-01],\n        ...,\n        [ 4.6385e-01, -2.6621e-02, -5.2346e-01,  ...,  2.6959e+01,\n          3.6158e-01, -4.6653e-01],\n        [-2.5534e-01,  3.0918e-01,  1.4617e-01,  ...,  3.6158e-01,\n          2.6692e+01, -4.4417e-01],\n        [ 3.3804e-01, -7.8089e-02, -2.5943e-01,  ..., -4.6653e-01,\n         -4.4417e-01,  2.8916e+01]], dtype=torch.float64)"
  },
  {
    "objectID": "sqrtm.html#subhransu-majis-methods",
    "href": "sqrtm.html#subhransu-majis-methods",
    "title": "sqrtm",
    "section": "Subhransu Maji’s method(s)",
    "text": "Subhransu Maji’s method(s)\nFrom https://github.com/msubhransu/matrix-sqrt\n\nsource\n\nsqrt_newton_schulz\n\n sqrt_newton_schulz (A, numIters=20, calc_error=False)\n\nSqrt of matrix via Newton-Schulz algorithm Modified from https://github.com/msubhransu/matrix-sqrt/blob/cc2289a3ed7042b8dbacd53ce8a34da1f814ed2f/matrix_sqrt.py#LL72C1-L87C19 # Forward via Newton-Schulz iterations (non autograd version) # Seems to be slighlty faster and has much lower memory overhead\n… Original code didn’t preserve device, had no batch dim checking -SHH\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nA\n\n\nmatrix to be sqrt-ified\n\n\nnumIters\nint\n20\nnumIters=7 found via experimentation\n\n\ncalc_error\nbool\nFalse\nsetting False disables Maji’s error reporting\n\n\n\n\nsource\n\n\nsqrt_newton_schulz_autograd\n\n sqrt_newton_schulz_autograd (A, numIters=20, calc_error=False)\n\nModified from from https://people.cs.umass.edu/~smaji/projects/matrix-sqrt/ “The drawback of the autograd approach [i.e., this approach] is that a naive implementation stores all the intermediate results. Thus the memory overhead scales linearly with the number of iterations which is problematic for large matrices.”\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nA\n\n\n\n\n\nnumIters\nint\n20\nfound experimentally by SHH, comparing w/ Li’s method\n\n\ncalc_error\nbool\nFalse\n\n\n\n\n\nsource\n\n\ncompute_error\n\n compute_error (A, sA)"
  },
  {
    "objectID": "sqrtm.html#error-tests",
    "href": "sqrtm.html#error-tests",
    "title": "sqrtm",
    "section": "Error tests",
    "text": "Error tests\n\nsa1, error = sqrt_newton_schulz_autograd( pd_mat.unsqueeze(0), numIters=20, calc_error=True ) \nprint(\"sa1 =\\n\",sa1)\nprint(\"error =\",error.detach().item())\n\nsa1 =\n tensor([[[ 2.6360e+01, -5.2896e-01,  4.6021e-01,  ...,  4.6384e-01,\n          -2.5535e-01,  3.3805e-01],\n         [-5.2896e-01,  2.5773e+01, -7.2415e-01,  ..., -2.6632e-02,\n           3.0917e-01, -7.8092e-02],\n         [ 4.6021e-01, -7.2415e-01,  2.5863e+01,  ..., -5.2344e-01,\n           1.4618e-01, -2.5943e-01],\n         ...,\n         [ 4.6384e-01, -2.6632e-02, -5.2344e-01,  ...,  2.6959e+01,\n           3.6150e-01, -4.6653e-01],\n         [-2.5535e-01,  3.0917e-01,  1.4618e-01,  ...,  3.6150e-01,\n           2.6692e+01, -4.4418e-01],\n         [ 3.3805e-01, -7.8092e-02, -2.5943e-01,  ..., -4.6653e-01,\n          -4.4418e-01,  2.8916e+01]]], dtype=torch.float64,\n       grad_fn=&lt;MulBackward0&gt;)\nerror = 4.759428080865442e-08\n\n\n\nsa2, error = sqrt_newton_schulz( pd_mat.unsqueeze(0), numIters=20, calc_error=True ) \nprint(\"sa2 =\\n\",sa2)\nprint(\"error =\",error.detach().item())\n\nsa2 =\n tensor([[[ 2.6360e+01, -5.2896e-01,  4.6021e-01,  ...,  4.6384e-01,\n          -2.5535e-01,  3.3805e-01],\n         [-5.2896e-01,  2.5773e+01, -7.2415e-01,  ..., -2.6632e-02,\n           3.0917e-01, -7.8092e-02],\n         [ 4.6021e-01, -7.2415e-01,  2.5863e+01,  ..., -5.2344e-01,\n           1.4618e-01, -2.5943e-01],\n         ...,\n         [ 4.6384e-01, -2.6632e-02, -5.2344e-01,  ...,  2.6959e+01,\n           3.6150e-01, -4.6653e-01],\n         [-2.5535e-01,  3.0917e-01,  1.4618e-01,  ...,  3.6150e-01,\n           2.6692e+01, -4.4418e-01],\n         [ 3.3805e-01, -7.8092e-02, -2.5943e-01,  ..., -4.6653e-01,\n          -4.4418e-01,  2.8916e+01]]], dtype=torch.float64,\n       grad_fn=&lt;MulBackward0&gt;)\nerror = 4.759428080865442e-08\n\n\n\nif use_li:\n    diff = sa1 - sq\n    print(\"diff = \\n\",diff)\n\ndiff = \n tensor([[[-3.7835e-05,  3.8437e-07,  8.7208e-06,  ..., -1.2816e-05,\n          -1.8744e-05,  1.3386e-05],\n         [ 3.8437e-07, -1.9896e-06,  2.2977e-06,  ..., -1.1004e-05,\n          -1.0735e-05, -3.3250e-06],\n         [ 8.7208e-06,  2.2977e-06, -7.5329e-06,  ...,  2.2518e-05,\n           1.9394e-05, -3.9655e-06],\n         ...,\n         [-1.2816e-05, -1.1004e-05,  2.2518e-05,  ..., -8.1416e-05,\n          -7.1274e-05, -1.4799e-06],\n         [-1.8744e-05, -1.0735e-05,  1.9394e-05,  ..., -7.1274e-05,\n          -8.0163e-05, -1.6137e-05],\n         [ 1.3386e-05, -3.3250e-06, -3.9655e-06,  ..., -1.4799e-06,\n          -1.6137e-05, -2.6324e-05]]], dtype=torch.float64,\n       grad_fn=&lt;SubBackward0&gt;)\n\n\n\nif use_li:\n    diff = sa2 - sq\n    print(\"diff = \\n\",diff)\n\ndiff = \n tensor([[[-3.7835e-05,  3.8437e-07,  8.7208e-06,  ..., -1.2816e-05,\n          -1.8744e-05,  1.3386e-05],\n         [ 3.8437e-07, -1.9896e-06,  2.2977e-06,  ..., -1.1004e-05,\n          -1.0735e-05, -3.3250e-06],\n         [ 8.7208e-06,  2.2977e-06, -7.5329e-06,  ...,  2.2518e-05,\n           1.9394e-05, -3.9655e-06],\n         ...,\n         [-1.2816e-05, -1.1004e-05,  2.2518e-05,  ..., -8.1416e-05,\n          -7.1274e-05, -1.4799e-06],\n         [-1.8744e-05, -1.0735e-05,  1.9394e-05,  ..., -7.1274e-05,\n          -8.0163e-05, -1.6137e-05],\n         [ 1.3386e-05, -3.3250e-06, -3.9655e-06,  ..., -1.4799e-06,\n          -1.6137e-05, -2.6324e-05]]], dtype=torch.float64,\n       grad_fn=&lt;SubBackward0&gt;)"
  },
  {
    "objectID": "sqrtm.html#speed-device-tests",
    "href": "sqrtm.html#speed-device-tests",
    "title": "sqrtm",
    "section": "Speed & device tests",
    "text": "Speed & device tests\n\nfrom aeiou.core import get_device\n\n\ndevice = get_device()\nprint('device = ',device)\nn,m = 1000, 1000\nwith torch.no_grad(): \n    k = torch.randn(n, m, device=device)\n    pd_mat2 = (k.t().matmul(k)) # Create a positive definite matrix, no grad\n\ndevice =  cuda\n\n\n\n# %%timeit\nif use_li:\n    sq2 = sqrtm_li(pd_mat2)\n\nResult of %%timeit:\n1.12 s ± 191 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\nprint(sq2)\n\nNameError: name 'sq2' is not defined\n\n\n\n# %%timeit\nsq3 = sqrt_newton_schulz(pd_mat2.unsqueeze(0), numIters=20)[0]\n\nResult of %%timeit:\n8.8 ms ± 23.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
  },
  {
    "objectID": "sqrtm.html#wrapper-around-our-method-of-choice",
    "href": "sqrtm.html#wrapper-around-our-method-of-choice",
    "title": "sqrtm",
    "section": "Wrapper around our method of choice:",
    "text": "Wrapper around our method of choice:\nTLDR, we’ll use Maji’s Newton-Schulz method. Newton-Schulz is an approximate iterative method rather than an exact matrix sqrt, however, with 7 iterations the error is below 1e-5, (presumably significantly) lower than other errors in the problem.\n\nsource\n\nsqrtm\n\n sqrtm (A, method='maji', numIters=20)\n\nwrapper function for matrix sqrt algorithm of choice. Also we’ll turn off all gradients\n\nsqrtm(pd_mat2, method='maji') - sqrtm(pd_mat2, method='li')\n\ntensor([[ 1.9073e-06,  1.5616e-05,  9.0003e-06,  ..., -8.9407e-07,\n         -3.7104e-05,  6.7353e-06],\n        [ 1.9193e-05, -6.1035e-05, -4.7386e-06,  ...,  7.8678e-06,\n          2.9802e-05, -5.8711e-06],\n        [ 7.5698e-06, -5.4836e-06, -3.8147e-05,  ...,  2.0236e-05,\n          1.6876e-06, -2.9024e-05],\n        ...,\n        [-3.3975e-06,  3.6955e-06,  2.2471e-05,  ..., -1.1444e-05,\n          3.6955e-06,  1.2971e-05],\n        [-3.6355e-05,  2.5883e-05,  7.5437e-06,  ...,  9.4771e-06,\n         -6.8665e-05,  6.7949e-06],\n        [ 4.2319e-06, -1.3113e-05, -2.6686e-05,  ...,  9.9763e-06,\n          1.1921e-05,  5.7220e-06]], device='cuda:0')"
  }
]