fad_pytorch
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

[Original FAD paper (PDF)](https://arxiv.org/pdf/1812.08466.pdf)

## Install

Work in progress. If you’re just finding this repo on GitHub, it may not
be ready yet.

``` sh
pip install fad_pytorch
```

## About

(Intended) Features:

- runs in parallel on multiple GPUs
- favors 48kHz sample rates
- can use CLAP embeddings
- favors ops in PyTorch instead of numpy
- allows dataset access via WebDataset (over s3://)
- operates on CPU, CUDA, or MPS

This is designed to be run as 3 command-line scripts in succession:

1.  `fad_gen.py`: produces directories of real & fake audio
2.  `fad_embed.py`: produces directories of *embeddings* of real & fake
    audio
3.  `fad_score.py`: reads the embeddings & generates FAD score, for real
    (“$r$”) and fake (“$f$”):

$$ FAD = || \mu_r - \mu_f ||^2 + tr\left(\Sigma_r + \Sigma_f - 2 \sqrt{\Sigma_r \Sigma_f}\right)$$

## Related Repos

There are \[several\] others, but this one is mine. These repos didn’t
have all the features I wanted, but I used them for inspiration:

- https://github.com/gudgud96/frechet-audio-distance
- https://github.com/google-research/google-research/tree/master/frechet_audio_distance:
  Goes with [Original FAD paper](https://arxiv.org/pdf/1812.08466.pdf)
- https://github.com/AndreevP/speech_distances
